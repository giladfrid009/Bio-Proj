{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from cv2 import VideoCapture\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from typing import Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcBackground(\n",
    "    video_path: str,\n",
    "    num_samples: int = 100,\n",
    "    image_transform: Callable[[np.ndarray], np.ndarray] = None,\n",
    ") -> np.ndarray:\n",
    "    # Open Video\n",
    "    cap = VideoCapture(video_path)\n",
    "\n",
    "    # Get Video Length\n",
    "    length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # Randomly select up to 50 frames\n",
    "    frame_ids = length * np.random.uniform(size=min(length, num_samples))\n",
    "\n",
    "    # Store selected frames in an array\n",
    "    frames = []\n",
    "    for fid in tqdm(frame_ids, desc=\"reading frames\"):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, fid)\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Apply transform if needed\n",
    "        if image_transform is not None:\n",
    "            frame = image_transform(frame)\n",
    "\n",
    "        # Convert to grayscale\n",
    "        frames.append(frame)\n",
    "\n",
    "    # Calculate the median along the time axis\n",
    "    median_frame = np.median(frames, axis=0).astype(dtype=np.uint8)\n",
    "\n",
    "    return median_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toGrayscale(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractBoxes(\n",
    "    image: np.ndarray,\n",
    "    background: np.ndarray,\n",
    "    diff_thresh: int = 75,\n",
    "    size_thresh: int = 40,\n",
    ") -> np.ndarray:\n",
    "    # Calculate difference between background and image\n",
    "    diff = np.abs(image.astype(np.int32) - background.astype(np.int32)).astype(np.uint8)\n",
    "\n",
    "    # Turn differences mask to black & white according to a threshold value\n",
    "    _, mask = cv2.threshold(diff, diff_thresh, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # find contours in the binary mask\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Populate bounding boxes\n",
    "    bboxes = []\n",
    "    for c in contours:\n",
    "        rect = cv2.boundingRect(c)\n",
    "\n",
    "        # Skip too small bounding boxes\n",
    "        if rect[2] < size_thresh and rect[3] < size_thresh:\n",
    "            continue\n",
    "\n",
    "        bboxes.append(rect)\n",
    "\n",
    "    return bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractRois(image: np.ndarray, bboxes: list, width: int = 200, height: int = 200):\n",
    "    rois = []\n",
    "    for box in bboxes:\n",
    "        x, y, w, h = box\n",
    "\n",
    "        # Calculate center of bbox\n",
    "        x_center, y_center = x + w // 2, y + h // 2\n",
    "\n",
    "        # Get bottom left corner\n",
    "        x0, y0 = x_center - width // 2, y_center - height // 2\n",
    "        x0, y0 = max(0, x0), max(0, y0)\n",
    "\n",
    "        roi = image[y0 : y0 + height, x0 : x0 + width]\n",
    "\n",
    "        rois.append(roi)\n",
    "\n",
    "    return rois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FindRois(\n",
    "    video_path: str,\n",
    "    video_background: np.ndarray,\n",
    "    background_diff_thresh: int = 75,\n",
    "    bbox_size_thresh: int = 40,\n",
    "    image_transform: Callable[[np.ndarray], np.ndarray] = None,\n",
    "):\n",
    "    cap = VideoCapture(video_path)\n",
    "\n",
    "    while True:\n",
    "        ret, image = cap.read()\n",
    "        if ret == False:\n",
    "            break\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "        if image_transform is not None:\n",
    "            imgTrans = image_transform(image)\n",
    "\n",
    "        bboxes = extractBoxes(imgTrans, background=video_background, diff_thresh=background_diff_thresh, size_thresh=bbox_size_thresh)\n",
    "\n",
    "        rois = extractRois(image, bboxes, width=200, height=200)\n",
    "\n",
    "        # Draw bboxes\n",
    "        for box in bboxes:\n",
    "            x, y, w, h = box\n",
    "\n",
    "            cv2.rectangle(image, (x, y), (x + w, y + h), (0, 0, 255), 3)\n",
    "\n",
    "        cv2.imshow(\"BBOXES\", image)\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_gray = calcBackground(\"worms.avi\", num_samples=100, image_transform=toGrayscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FindRois(\"worms.avi\", bg_gray, image_transform=toGrayscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio-proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
